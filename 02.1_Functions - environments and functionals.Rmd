---
title: "02.1 Functions: Environments and Functionals"
author: "Abby Lewis"
date: "2023-10-05"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(purrr)
library(rlang)
```

# Functions, continued

This document is a continuation of 02_Functions.Rmd

## Lexical scoping

Here we'll discuss __scoping__, the act of finding the value associated with a name.

For example, what will the following code return, 10 or 20?

```{r, results = "hide"}
x <- 10
g01 <- function() {
  x <- 20
  x
}

g01()
```

In this section, you'll learn the formal rules of scoping. 

A deeper understanding of scoping will help you to use more advanced functional programming tools, and eventually, even to write tools that translate R code into other languages.

### Environments

To understand scoping, it is helpful to have a general awareness of environments in R

The job of an environment is to associate, or __bind__, a set of names to a set of values. You can think of an environment as a bag of names, with no implied order (i.e. it doesn't make sense to ask which is the first element in an environment). For that reason, we'll draw the environment as so:

```{r, echo = FALSE, out.width = NULL}
knitr::include_graphics("../diagrams/environments/bindings.png")
```

### Lexical scoping

R uses __lexical scoping__: it looks up the values of names based on how a function is defined, not how it is called. 

__Parent__ environments are what is used to implement lexical scoping. Every environment has a __parent__, another environment.

If a name is not found in an environment, then R will look in its parent (and so on).  You can set the parent environment by supplying an unnamed argument to `env()`. If you don't supply it, it defaults to the current environment. In the code below, `e2a` is the parent of `e2b`.

In diagrams, the parent is shown as a small pale blue circle and arrow that points to another environment.

```{r}
e2a <- env(d = 4, e = 5)
e2b <- env(e2a, a = 1, b = 2, c = 3)
```
```{r, echo = FALSE, out.width = NULL}
knitr::include_graphics("../diagrams/environments/parents.png")
```

Each package attached by `library()` or `require()` becomes one of the parents of the global environment. The immediate parent of the global environment is the last package you attached, the parent of that package is the second to last package you attached, ... 

To save space, we typically won't draw all the ancestors; just remember whenever you see a pale blue circle, there's a parent environment somewhere. 

You can find the parent of an environment with `env_parent()`:

```{r}
env_parent(e2b)
env_parent(e2a)
```

R's lexical scoping follows four primary rules:

* Name masking
* Functions versus variables
* A fresh start
* Dynamic lookup

### Name masking

The basic principle of lexical scoping is that names defined inside a function mask names defined outside a function. This is illustrated in the following example.

```{r}
x <- 10
y <- 20
g02 <- function() {
  x <- 1
  y <- 2
  c(x, y)
}
g02()
```

If a name isn't defined inside a function, R looks one level up.

```{r}
x <- 2
g03 <- function() {
  y <- 1
  c(x, y)
}
g03()

# And this doesn't change the previous value of y
y
```

### Functions versus variables

When a function and a non-function share the same name (they must, of course, reside in different environments), applying these rules gets a little more complicated. When you use a name in a function call, R ignores non-function objects when looking for that value. For example, in the code below, `g09` takes on two different values:

```{r}
g09 <- function(x) x + 100
g10 <- function() {
  g09 <- 10
  g09(g09)
}
g10()
```

For the record, using the same name for different things is confusing and best avoided!

### A fresh start

What happens to values between invocations of a function? Consider the example below. What will happen the first time you run this function? What will happen the second time? 

```{r, results = "hide"}
g11 <- function() {
  #`exists()` returns `TRUE` if there's a variable with that name and returns `FALSE` if not
  if (!exists("a")) {
    a <- 1
  } else {
    a <- a + 1
  }
  return(a)
}

g11()
g11()
```

Every time a function is called a new environment is created to host its execution. This means that a function has no way to tell what happened the last time it was run; each invocation is completely independent. 

### Dynamic lookup

Lexical scoping determines where, but not when to look for values. R looks for values when the function is run, not when the function is created. Together, these two properties tell us that the output of a function can differ depending on the objects outside the function's environment:

```{r}
g12 <- function() {x + 1}
x <- 15
g12()

#What if we change x?
```

This behavior can be quite annoying. If you make a spelling mistake in your code, you won't get an error message when you create the function. And depending on the variables defined in the global environment, you might not even get an error message when you run the function. 

To detect this problem, use `codetools::findGlobals()`. This function lists all the external dependencies (unbound symbols) within a function:

```{r}
codetools::findGlobals(g12)
```

To solve this problem, you can manually change the function's environment to the `emptyenv()`, an environment which contains nothing:

```{r, error = TRUE}
environment(g12) <- emptyenv()
g12()
```

The problem and its solution reveal why this seemingly undesirable behaviour exists: R relies on lexical scoping to find _everything_, from the obvious, like `mean()`, to the less obvious, like `+` or even `{`. This gives R's scoping rules a rather beautiful simplicity.

### Debugging

Because functions are their own environment, it can be hard to figure out why code fails. `browser()` helps to address this. Here is just a taste of `browser()`. The debugging chapter of the Wickham book provides more info.

```{r}
g13 <- function(x) {
  z <- x + 2
  char <- paste0("x + 2 is ", z)
  output <- paste0("Log(x + 2) is ", log(char))
  return()
}

g13(12)
```

* Next, `n`: executes the next step in the function. If you have a
  variable named `n`, you'll need `print(n)` to display its value.

* Step into, ![](screenshots/step-into.png){width=20} or `s`: 
  works like next, but if the next step is a function, it will step into that
  function so you can explore it interactively.

* Finish, ![](screenshots/finish-loop.png){width=20} or `f`: 
  finishes execution of the current loop or function.

* Continue, `c`: leaves interactive debugging and continues regular execution
  of the function. This is useful if you've fixed the bad state and want to
  check that the function proceeds correctly.

* Stop, `Q`: stops debugging, terminates the function, and returns to the global
  workspace. Use this once you've figured out where the problem is, and you're
  ready to fix it and reload the code.

### Exercises

1. What does the following code return? Why? Describe how each of the three
   `c`'s is interpreted.

```{r, eval = FALSE}
c <- 10
c(c = c)
```

2. What are the four principles that govern how R looks for values?

3. What does the following function return? Make a prediction before 
   running the code yourself.

```{r, results = "hide"}
f <- function(x) {
  f <- function(x) {
    f <- function() {
      x ^ 2
    }
    f() + 1
  }
  f(x) * 2
}
f(10)
```

## Lazy evaluation

In R, function arguments are __lazily evaluated__: they're only evaluated if accessed. For example, this code doesn't generate an error because `x` is never used:

```{r}
h01 <- function(x) {
  #what happens if we put x in the body?
  return(10)
}
h01(stop("This is an error!"))
```

This is an important feature because it allows you to do things like include potentially expensive computations in function arguments that will only be evaluated if needed.

### Default arguments

Thanks to lazy evaluation, default values can be defined in terms of other arguments, or even in terms of variables defined later in the function:

```{r}
h04 <- function(x = 1, 
                y = x * 2, 
                z = a + b) {
  
  a <- 10
  b <- 100
  
  c(x, y, z)
}

h04()
```

Many base R functions use this technique, so it is helpful to know. However, but I don't recommend using this when writing your own functions. It makes the code harder to understand: to predict _what_ will be returned, you need to know the exact order in which default arguments are evaluated.

The evaluation environment is slightly different for default and user supplied arguments, as default arguments are evaluated inside the function. This means that seemingly identical calls can yield different results. It's easiest to see this with an extreme example:

```{r, eval = FALSE}
h05 <- function(x = ls()) {
  a <- 1
  x
}

# ls() evaluated inside h05:
h05()
#> [1] "a" "x"

# ls() evaluated in global environment:
h05(ls())
#> [1] "h05"
```

## `...`  (dot-dot-dot)

Functions can have a special argument `...` (pronounced dot-dot-dot). With it, a function can take any number of additional arguments. In other programming languages, this type of argument is often called _varargs_ (short for variable arguments), and a function that uses it is said to be variadic. 

You can also use `...` to pass those additional arguments on to another function.

```{r}
i01 <- function(y, z) {
  list(y = y, z = z)
}

i02 <- function(x, ...) {
  i01(...)
}

str(i02(x = 1, y = 2, z = 3))
```

For an example of where `...` may be useful, consider `lapply()`. Here, `lapply()` uses `...` to pass `na.rm` on to `mean()`:
    
```{r}
x <- list(c(1, 3, NA), c(4, NA, 6))
str(lapply(x, mean, na.rm = TRUE))
```

Using `...` comes with two downsides:

*   When you use it to pass arguments to another function, you have to 
    carefully explain to the user where those arguments go. This makes it
    hard to understand what you can do with functions like `lapply()` and 
    `plot()`.
    
*   A misspelled argument will not raise an error. This makes it easy for 
    typos to go unnoticed:

```{r}
sum(1, 2, NA, na_rm = TRUE)
```

## Function documentation

Developing strong code documentation habits will help *you* and others use the functions you write! When creating an R package, the following documentation format is used by`roxygen2` to create necessary metadata, and provides a reasonable starting place for documenting your own functions

Once the function definition exists, put your cursor somewhere in it and do Code > Insert Roxygen Skeleton to get a great head start on the roxygen comment.

```{r}
some_function <- function(x, y, z) {
  return(list(x, y, z))
}
```

Read more in the R packages book by Hadley Wickham here: https://r-pkgs.org/man.html

### Exercises

1. Rewrite the following code snippets into prefix form:

```{r, eval = FALSE}
1 + 2 + 3

1 + (2 + 3)

if (length(x) <= 5) x[[5]] else x[[n]]
```

2.  Clarify the following list of odd function calls:

```{r, eval = FALSE}
x <- sample(replace = TRUE, 20, x = c(1:10, NA))
y <- runif(min = 0, max = 1, 20)
cor(m = "k", y = y, u = "p", x = x)
```


3. Explain why the following code fails:

```{r, eval = FALSE}
modify(get("x"), 1) <- 10
#> Error: target of assignment expands to non-language object
```

4. Create a replacement function that modifies a random location in a vector.

5. Write your own version of `+` that pastes its inputs together if they are 
   character vectors but behaves as usual otherwise. In other words, make this 
   code work:
   
```{r, eval = FALSE}
1 + 2
#> [1] 3

"a" + "b"
#> [1] "ab"
```

6. Create a list of all the replacement functions found in the base package. 
   Which ones are primitive functions? (Hint: use `apropos()`.)

7. What are valid names for user-created infix functions?

8. Create an infix `xor()` operator.

9. Create infix versions of the set functions `intersect()`, `union()`, and
   `setdiff()`. You might call them `%n%`, `%u%`, and `%/%` to match 
   conventions from mathematics.
   
## Functionals

> To become significantly more reliable, code must become more transparent.
> In particular, nested conditions and loops must be viewed with great
> suspicion. Complicated control flows confuse programmers. Messy code often
> hides bugs.
>
> --- Bjarne Stroustrup

A __functional__ is a function that takes a function as an input and returns a vector as output. 

At the start of our functions unit, we tested multiple methods for replacing NAs, each with sequentially less code and potential for errors. Functionals take this one step further

Generate two sample datasets
```{r}
set.seed(1014) # Set seed controls random number generation, allowing for consistent results
# 1 Generate dataset with -99 as NA
df1 <- data.frame(replicate(6, sample(c(1:10, -99), 6, rep = TRUE))) 
names(df1) <- letters[1:6] # Assign column names
# 2 Generate dataset with -999 as NA
df2 <- data.frame(replicate(6, sample(c(1:10, -999), 6, rep = TRUE))) # Generate dataset
names(df2) <- letters[1:6] # Assign column names
```

Switch numeric missing values to NA
```{r}
# OPTION 1: brute force
# e.g., df1$a[df1$a == -99] <- NA, repeated for every column

# OPTION 2: For loops 
# e.g., the following code repeated for every dataset
#for(column in colnames(df1)){
#  fixed_values <- df1[[column]] #isolate column
#  fixed_values[fixed_values== -99] <- NA #replace NAs
#  df1[column] <- fixed_values
#}

# OPTION 3: function
# Function
fix_nas <- function(df, vals) {
  for (column in colnames(df)) {
    fixed_values <- df[[column]] #Save this column as a vector
    fixed_values[fixed_values %in% vals] <- NA #Replace val with NA
    df[column] <- fixed_values #Fill in the original dataframe
  }
  df
}

fix_nas(df1, c(-99,-999))
fix_nas(df2, c(-99,-999))

#OPTION 4: functional
#map(list(dfs), function, vals)

```

## My first functional: `map()`

The most fundamental functional is `purrr::map()`. It takes a vector and a function, calls the function once for each element of the vector, and returns the results in a list. 

Graphically:

```{r, echo = FALSE, out.width = NULL}
knitr::include_graphics("../diagrams/functionals/map.png")
```

The implementation of `map()` is quite simple. We allocate a list the same length as the input, and then fill in the list with a for loop. 

### Producing atomic vectors

`map()` returns a list, which makes it the most general of the map family because you can put anything in a list. But it is inconvenient to return a list when a simpler data structure would do, so there are four more specific variants: `map_lgl()`, `map_int()`, `map_dbl()`, and `map_chr()`. Each returns an atomic vector of the specified type:

```{r}
# map_chr() always returns a character vector
map_chr(mtcars, typeof)

# map_lgl() always returns a logical vector
map_lgl(mtcars, is.double)

# map_int() always returns a integer vector
n_unique <- function(x) length(unique(x))
map_int(mtcars, n_unique)

# map_dbl() always returns a double vector
map_dbl(mtcars, mean)
```

### Anonymous functions and shortcuts

Instead of using `map()` with an existing function, you can create an inline anonymous function:

```{r}
map_dbl(mtcars, function(x) length(unique(x)))
```

Anonymous functions are very useful, but the syntax is verbose. So purrr supports a special shortcut:

```{r}
map_dbl(mtcars, ~ length(unique(.x)))
```

This works because all purrr functions translate formulas, created by `~` (pronounced "twiddle"), into functions. You can see what's happening behind the scenes by calling `as_mapper()`:

```{r}
as_mapper(~ length(unique(.x)))
```

The function arguments look a little quirky but allow you to refer to `.` for one argument functions, `.x` and `.y` for two argument functions, and `..1`, `..2`, `..3`, etc, for functions with an arbitrary number of arguments. `.` remains for backward compatibility but I don't recommend using it because it's easily confused with the `.` used by magrittr's pipe.

This shortcut is particularly useful for generating random data:

```{r}
x <- map(1:3, ~ runif(2))
str(x)
```

Reserve this syntax for short and simple functions. A good rule of thumb is that if your function spans lines or uses `{}`, it's time to give it a name.

The map functions also have shortcuts for extracting elements from a vector, powered by  `purrr::pluck()`. You can use a character vector to select elements by name, an integer vector to select by position, or a list to select by both name and position. These are very useful for working with deeply nested lists, which often arise when working with JSON. 

```{r, error = TRUE}
x <- list(
  list(-1, x = 1, y = c(2), z = "a"),
  list(-2, x = 4, y = c(5, 6), z = "b"),
  list(-3, x = 8, y = c(9, 10, 11))
)

# Select by name
map_dbl(x, "x")

# Or by position
map_dbl(x, 1)

# Or by both
map_dbl(x, list("y", 1))

# You'll get an error if a component doesn't exist:
map_chr(x, "z")

# Unless you supply a .default value
map_chr(x, "z", .default = NA)
```

### Passing arguments with `...` 

You have already seen above that map functions pass `...` along as function arguments:

```{r}
map_dbl(x, mean, na.rm = TRUE)
```

This is easiest to understand with a picture: any arguments that come after `f` in the call to `map()` are inserted _after_ the data in individual calls to `f()`:

```{r, echo = FALSE, out.width = NULL}
knitr::include_graphics("../diagrams/functionals/map-arg.png")
```

It's important to note that these arguments are not decomposed; or said another way, `map()` is only vectorised over its first argument. If an argument after `f` is a vector, it will be passed along as is:

```{r, echo = FALSE, out.width = NULL}
knitr::include_graphics("../diagrams/functionals/map-arg-recycle.png")
```

## Map variants

There are 23 primary variants of `map()`. So far, you've learned about five (`map()`, `map_lgl()`, `map_int()`, `map_dbl()` and `map_chr()`). That means that you've got 18 (!!) more to learn. That sounds like a lot, but fortunately the design of purrr means that you only need to learn five new ideas:

* Output same type as input with `modify()`
* Iterate over two inputs with `map2()`.
* Iterate with an index using `imap()`
* Return nothing with `walk()`.
* Iterate over any number of inputs with `pmap()`.

The map family of functions has orthogonal input and outputs, meaning that we can organise all the family into a matrix, with inputs in the rows and outputs in the columns. Once you've mastered the idea in a row, you can combine it with any column; once you've mastered the idea in a column, you can combine it with any row. That relationship is summarised in the following table:

|                       | List     | Atomic            | Same type   | Nothing   |
|-----------------------|----------|-------------------|-------------|-----------|
| One argument          | `map()`  | `map_lgl()`, ...  | `modify()`  | `walk()`  |
| Two arguments         | `map2()` | `map2_lgl()`, ... | `modify2()` | `walk2()` |
| One argument + index  | `imap()` | `imap_lgl()`, ... | `imodify()` | `iwalk()` |
| N arguments           | `pmap()` | `pmap_lgl()`, ... | ---         | `pwalk()` |

We won't cover any of these in class, but Hadley's book has more information.

### Exercises

1.  How does `apply()` arrange the output? Read the documentation and perform 
    some experiments.

1.  What do `eapply()` and `rapply()` do? Does purrr have equivalents?

1.  Challenge: read about the 
    [fixed point algorithm](https://mitpress.mit.edu/sites/default/files/sicp/full-text/book/book-Z-H-12.html#%25_idx_1096).
    Complete the exercises using R.
